{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5219471e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### kmedoids results -- random 100 pairs: {1: 0.5176, 2: 0.3712, 3: 0.2796, 4: 0.2342, 5: 0.2005}\n",
      "### kmedoids results -- random 100 pairs: {1: 0.4844, 2: 0.2573, 3: 0.2063, 4: 0.1816, 5: 0.1528}\n",
      "### kmedoids results -- random 100 pairs: {1: 0.5106, 2: 0.2661, 3: 0.1691, 4: 0.1413, 5: 0.1287}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "warnings.simplefilter(\"ignore\", FutureWarning)\n",
    "\n",
    "import random\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "\n",
    "def kmeans_from_points(points):\n",
    "    ret = {}\n",
    "    for n_clusters in range(1, 6):\n",
    "        kmed = KMeans(\n",
    "            n_clusters=n_clusters,\n",
    "            algorithm=\"lloyd\",\n",
    "            init=\"k-means++\",\n",
    "        )\n",
    "        kmed.fit(points)\n",
    "        labels = kmed.labels_\n",
    "        cluster_centers = kmed.cluster_centers_\n",
    "\n",
    "        dists = []\n",
    "        for c in range(n_clusters):\n",
    "            idx = np.where(labels == c)[0]\n",
    "            if idx.size <= 1:\n",
    "                dists.append(0.0)\n",
    "            else:\n",
    "                cluster = points[idx]\n",
    "                cluster_distance = np.abs(cluster - cluster_centers[c:c+1])\n",
    "                dists.append(cluster_distance.mean())\n",
    "        ret[n_clusters] = round(np.mean(dists), 4)\n",
    "    return ret\n",
    "\n",
    "def clustering(tensor):\n",
    "    N, D = tensor.shape\n",
    "    print(f\"### kmedoids results -- random {N} pairs: {kmeans_from_points(tensor)}\")\n",
    "\n",
    "N, D = 100, 2\n",
    "points = np.random.rand(N, D)\n",
    "\n",
    "O = points.copy()\n",
    "O = 2.0 * O - 1.0\n",
    "clustering(O)\n",
    "A = points.copy()\n",
    "A[:N//2] = -1.0 * A[:N//2]\n",
    "A[N//2:] = A[N//2:]\n",
    "clustering(A)\n",
    "B = points.copy()\n",
    "B[:N//3] = 0.66 * B[:N//3] - 1.0\n",
    "B[N//3:2*N//3] = 0.66 * B[N//3:2*N//3] - 0.33\n",
    "B[2*N//3:] = 0.66 * B[2*N//3:] + 0.33\n",
    "clustering(B)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0ff9e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====qwen3_base_grpo.log=====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics based on 560 DAPO examples\n",
      "### cluster results -- all: [(1, 8.5957), (2, 2.9884), (3, 1.7006), (4, 1.1678), (5, 0.8)]\n",
      "### cluster results -- last: [(1, 10.4557), (2, 3.8803), (3, 2.3285), (4, 1.6606), (5, 1.1696)]\n",
      "=====grpo_bl_20.log=====\n",
      "Statistics based on 560 DAPO examples\n",
      "### cluster results -- all: [(1, 2.3628), (2, 1.0793), (3, 0.8146), (4, 0.6744), (5, 0.5827)]\n",
      "### cluster results -- last: [(1, 4.3099), (2, 2.1138), (3, 1.5912), (4, 1.3174), (5, 1.1388)]\n",
      "=====grpo_bl_250.log=====\n",
      "Statistics based on 560 DAPO examples\n",
      "### cluster results -- all: [(1, 1.7835), (2, 0.9614), (3, 0.7257), (4, 0.6052), (5, 0.5289)]\n",
      "### cluster results -- last: [(1, 1.9829), (2, 1.0529), (3, 0.7961), (4, 0.6587), (5, 0.5722)]\n",
      "=====grpo_ppl_250.log=====\n",
      "Statistics based on 560 DAPO examples\n",
      "### cluster results -- all: [(1, 1.7167), (2, 0.9027), (3, 0.6906), (4, 0.5752), (5, 0.5028)]\n",
      "### cluster results -- last: [(1, 3.0139), (2, 1.5585), (3, 1.1969), (4, 0.9983), (5, 0.8762)]\n",
      "=====grpo_bl_400_1620.log=====\n",
      "Statistics based on 555 DAPO examples\n",
      "### cluster results -- all: [(1, 1.7656), (2, 0.9408), (3, 0.7079), (4, 0.5795), (5, 0.5044)]\n",
      "### cluster results -- last: [(1, 2.1482), (2, 1.1499), (3, 0.8596), (4, 0.7054), (5, 0.6087)]\n",
      "=====qwen3_base_ppo.log=====\n",
      "Statistics based on 560 DAPO examples\n",
      "### cluster results -- all: [(1, 2.8968), (2, 1.845), (3, 1.5326), (4, 1.3484), (5, 1.2271)]\n",
      "### cluster results -- last: [(1, 4.8906), (2, 3.1152), (3, 2.5865), (4, 2.2767), (5, 2.0695)]\n",
      "=====ppo_bl_250.log=====\n",
      "Statistics based on 560 DAPO examples\n",
      "### cluster results -- all: [(1, 6.2525), (2, 3.2571), (3, 2.5163), (4, 2.1014), (5, 1.8374)]\n",
      "### cluster results -- last: [(1, 7.29), (2, 3.8284), (3, 2.9447), (4, 2.4667), (5, 2.1557)]\n",
      "=====ppo_mhead_250.log=====\n",
      "Statistics based on 560 DAPO examples\n",
      "### cluster results -- all: [(1, 6.1504), (2, 3.207), (3, 2.4653), (4, 2.0877), (5, 1.831)]\n",
      "### cluster results -- last: [(1, 6.4504), (2, 3.338), (3, 2.5809), (4, 2.1787), (5, 1.9112)]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "from collections import defaultdict\n",
    "\n",
    "def parse_defaultdict(line):\n",
    "    target = \"defaultdict(<class 'float'>, \"\n",
    "    st = line.find(target)\n",
    "    dict_str = line[st:].replace(target, \"\")[:-1]  # strip trailing \")\"\n",
    "    parsed_dict = ast.literal_eval(dict_str)\n",
    "    return parsed_dict\n",
    "\n",
    "def parse_dict(line):\n",
    "    st = line.find(\": {\") + 2\n",
    "    parsed_dict = ast.literal_eval(line[st:])\n",
    "    return parsed_dict\n",
    "\n",
    "def clustering(path):\n",
    "    counts = [0, 0, 0]\n",
    "    norm = defaultdict(float)\n",
    "    cluster_all = defaultdict(float)\n",
    "    cluster_last = defaultdict(float)\n",
    "    with open(path, \"r\") as fin:\n",
    "        for line in fin:\n",
    "            line = line.strip()\n",
    "            if \"### grad accum\" in line:\n",
    "                counts[0] += 1\n",
    "                for k,v in parse_defaultdict(line).items():\n",
    "                    k = \".\".join(k.split(\".\")[:3])\n",
    "                    norm[k] += v\n",
    "            if \"### kmedoids results -- all\" in line:\n",
    "                counts[1] += 1\n",
    "                for k,v in parse_dict(line).items():\n",
    "                    cluster_all[k] += v\n",
    "            if \"### kmedoids results -- last\" in line:\n",
    "                counts[2] += 1\n",
    "                for k,v in parse_dict(line).items():\n",
    "                    cluster_last[k] += v\n",
    "\n",
    "    print(f\"Statistics based on {counts[0]} DAPO examples\")\n",
    "    # norm = [(round(v,4), k) for k,v in norm.items()]\n",
    "    # norm = \"\\n\".join(f\"{x[0]} {x[1]}\" for x in sorted(norm, key=lambda x: -x[0]))\n",
    "    # print(f\"### grad accum: \\n{norm}\")\n",
    "    cluster_all = list((i, round(cluster_all[i]/counts[1],4)) for i in range(1, 6))\n",
    "    print(f\"### cluster results -- all: {cluster_all}\")\n",
    "    cluster_last = list((i, round(cluster_last[i]/counts[2],4)) for i in range(1, 6))\n",
    "    print(f\"### cluster results -- last: {cluster_last}\")\n",
    "\n",
    "base = \"/apdcephfs_cq10/share_1603164/user/lfsong/exp.tencent_chat/grad_sim_logs\"\n",
    "for filename in [\"qwen3_base_grpo.log\", \"grpo_bl_20.log\", \"grpo_bl_250.log\", \"grpo_ppl_250.log\", \"grpo_bl_400_1620.log\", \n",
    "                 \"qwen3_base_ppo.log\", \"ppo_bl_250.log\", \"ppo_mhead_250.log\"]:\n",
    "    path = os.path.join(base, filename)\n",
    "    print(f\"====={filename}=====\")\n",
    "    clustering(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26894333",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import MDS\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def kmedoids_from_distance(distance):\n",
    "    ret = {}\n",
    "    for n_clusters in range(1, 6):\n",
    "        kmed = KMedoids(\n",
    "            n_clusters=n_clusters,\n",
    "            metric=\"precomputed\",\n",
    "            method=\"pam\",\n",
    "            init=\"k-medoids++\",\n",
    "        )\n",
    "        kmed.fit(distance)\n",
    "        labels = kmed.labels_\n",
    "        medoid_indices = kmed.medoid_indices_\n",
    "\n",
    "        dists = []\n",
    "        for c in range(n_clusters):\n",
    "            idx = np.where(labels == c)[0]\n",
    "            if idx.size <= 1:\n",
    "                dists.append(0.0)\n",
    "            else:\n",
    "                dists.append(distance[idx, medoid_indices[c]].sum() / (idx.size - 1))\n",
    "        ret[n_clusters] = round(np.mean(dists), 4)\n",
    "    return ret\n",
    "\n",
    "# dist_matrix: NxN 距离矩阵\n",
    "mds = MDS(n_components=2, dissimilarity='precomputed', random_state=42)\n",
    "X_2d = mds.fit_transform(dist_matrix)\n",
    "\n",
    "plt.scatter(X_2d[:, 0], X_2d[:, 1], c=labels, cmap='tab10')\n",
    "plt.title('MDS 2D projection')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
